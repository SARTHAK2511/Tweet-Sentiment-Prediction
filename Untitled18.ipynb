{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xGXSsZU0r8R",
        "outputId": "d6848ed8-bea1-4063-dec4-65d2b53a86c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "from os import getcwd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import twitter_samples\n",
        "import joblib"
      ],
      "metadata": {
        "id": "lssBwJ2q1mgZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6GWV5zb1m5p",
        "outputId": "bd77fc96-8dd5-4469-cd70-60134cb08a33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)"
      ],
      "metadata": {
        "id": "fgBLQplq19gI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # removing stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # removing old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # removing hyperlinks\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
        "    # removing hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # removing stopwords\n",
        "                word not in string.punctuation):  # removing punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "y0bGcTIQ2AOR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, ys):\n",
        "    \"\"\"Build frequencies.\n",
        "    Input:\n",
        "        tweets: a list of tweets\n",
        "        ys: an m x 1 array with the sentiment label of each tweet\n",
        "            (either 0 or 1)\n",
        "    Output:\n",
        "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
        "        frequency\n",
        "    \"\"\"\n",
        "    # Convert np array to list since zip needs an iterable.\n",
        "    # The squeeze is necessary or the list ends up with one element.\n",
        "    # Also note that this is just a NOP if ys is already a list.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Start with an empty dictionary and populate it by looping over all tweets\n",
        "    # and over all processed words in each tweet.\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs"
      ],
      "metadata": {
        "id": "9y-YCAWu2Xsn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the sets of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# split the data into two pieces, one for training and one for testing (validation set)\n",
        "test_pos   = all_positive_tweets[4000:]\n",
        "train_pos  = all_positive_tweets[:4000]\n",
        "test_neg   = all_negative_tweets[4000:]\n",
        "train_neg  = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x  = test_pos + test_neg\n",
        "\n",
        "# avoid assumptions about the length of all_positive_tweets\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y  = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
      ],
      "metadata": {
        "id": "m9XpX6w_4qHV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
        "\n",
        "# print cleaned tweet\n",
        "print(process_tweet(custom_tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttIongvn5Uav",
        "outputId": "56b6f419-a74b-41de-de36-0c36d7ea04de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'great', 'day', ':)', 'good', 'morn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tweets(result, tweets, ys):\n",
        "    '''\n",
        "    Input:\n",
        "        result: a dictionary that will be used to map each pair to its frequency\n",
        "        tweets: a list of tweets\n",
        "        ys: a list corresponding to the sentiment of each tweet (either 0 or 1)\n",
        "    Output:\n",
        "        result: a dictionary mapping each pair to its frequency\n",
        "    '''\n",
        "    for y,tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in result:\n",
        "                result[pair] += 1\n",
        "            else:\n",
        "                result[pair] = 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "5Tmun6gN6LCj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = {}\n",
        "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
        "ys = [1,0,0,0,0]\n",
        "count_tweets(result, tweets, ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTZ-vTZd6ZXd",
        "outputId": "fe6e41ad-1c97-4ab8-a8a9-828a5ea208e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = count_tweets({}, train_x, train_y)"
      ],
      "metadata": {
        "id": "5ULau4aA6kxV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary from (word, label) to how often the word appears\n",
        "        train_x: a list of tweets\n",
        "        train_y: a list of labels correponding to the tweets (0,1)\n",
        "    Output:\n",
        "        logprior: the log prior. (equation 3 above)\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "    N_pos=N_neg=V_pos=V_neg=0\n",
        "\n",
        "    for pair in freqs.keys():\n",
        "        if pair[1] > 0:\n",
        "            V_pos += 1\n",
        "            N_pos += freqs[pair]\n",
        "\n",
        "        else:\n",
        "            V_neg += 1\n",
        "            N_neg += freqs[pair]\n",
        "\n",
        "    D = train_y.shape[0]\n",
        "    D_pos = train_y[train_y == 1].shape[0]\n",
        "    D_neg = train_y[train_y == 0].shape[0]\n",
        "    logprior  = np.log(D_pos / D) - np.log(D_neg / D)\n",
        "\n",
        "    for word in vocab:\n",
        "        freq_pos = freqs.get((word, 1), 0)\n",
        "        freq_neg = freqs.get((word, 0), 0)\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "    return logprior, loglikelihood"
      ],
      "metadata": {
        "id": "hivNPHKM6uu1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprior,loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpzwcKF_9npO",
        "outputId": "472378a9-0c5d-4886-adc9-760dbcad4bba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "9161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Output:\n",
        "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
        "\n",
        "    '''\n",
        "    word_l = process_tweet(tweet)\n",
        "    p = 0\n",
        "    p += logprior\n",
        "    for word in word_l:\n",
        "\n",
        "        if word in loglikelihood:\n",
        "\n",
        "            p += loglikelihood[word]\n",
        "    return p"
      ],
      "metadata": {
        "id": "ntjCuTwx9oAe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'She smiled.'\n",
        "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQq6U4859xSr",
        "outputId": "c72afa7b-0618-4e57-925a-cbb91cf75dca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is 1.557492820301094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: A list of tweets\n",
        "        test_y: the corresponding labels for the list of tweets\n",
        "        logprior: the logprior\n",
        "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly)/(total # of tweets)\n",
        "    \"\"\"\n",
        "    acuracy = 0\n",
        "    y_hats = []\n",
        "    for tweet in test_x:\n",
        "\n",
        "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
        "\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "\n",
        "            y_hat_i = 0\n",
        "\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    error = np.mean(np.abs(np.asarray(y_hats) - test_y))\n",
        "\n",
        "    accuracy = 1 - error\n",
        "\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "uiC6lDs19zjv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naive Bayes accuracy = %0.4f\" % (test_naive_bayes(test_x,test_y,logprior,loglikelihood)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiVZqEM--B8y",
        "outputId": "e218adfc-314b-49c1-d20d-741b159998ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy = 0.9955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_tweets = ['I am happy', 'I am bad', 'this movie should have been great.',\n",
        "               'great', 'great great', 'great great great', 'great great great great']\n",
        "\n",
        "for tweet in some_tweets:\n",
        "    p = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
        "    print(f'{tweet} -> {p:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DTMNhbb-EL0",
        "outputId": "552fe9c6-ba85-4c71-ceba-da73e6e38ac6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 2.14\n",
            "I am bad -> -1.31\n",
            "this movie should have been great. -> 2.12\n",
            "great -> 2.13\n",
            "great great -> 4.26\n",
            "great great great -> 6.39\n",
            "great great great great -> 8.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "my_tweet = 'you are bad :('\n",
        "naive_bayes_predict(my_tweet, logprior, loglikelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEM7vqtF-G5-",
        "outputId": "8665b442-e813-4141-8fa3-5d52927936a7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-8.837962482271395"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup(freqs, word, label):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    freqs: A dictionary with keys as (word, label) and values as the count of word occurrences for the given label.\n",
        "    word: The word you want to look up.\n",
        "    label: The label (1 for positive, 0 for negative) you want to search for.\n",
        "\n",
        "    Output:\n",
        "    The count of the word in the specified label. If the word-label pair doesn't exist in freqs, return 0.\n",
        "    \"\"\"\n",
        "    if (word, label) in freqs:\n",
        "        return freqs[(word, label)]\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_ratio(freqs, word):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    freqs: A dictionary containing the words and their frequencies.\n",
        "    word: The word for which you want to calculate the positive-to-negative ratio.\n",
        "\n",
        "    Output:\n",
        "    A dictionary with keys 'positive', 'negative', and 'ratio'.\n",
        "    Example: {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "    \"\"\"\n",
        "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
        "    pos_neg_ratio['positive'] = lookup(freqs, word, 1)\n",
        "    pos_neg_ratio['negative'] = lookup(freqs, word, 0)\n",
        "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive'] + 1) / (pos_neg_ratio['negative'] + 1)\n",
        "\n",
        "    return pos_neg_ratio\n"
      ],
      "metadata": {
        "id": "_KcWyFre-LID"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratio(freqs,'happi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v1GxNJr-QvH",
        "outputId": "20c0d5d6-b045-4374-d558-03e13f6d0d53"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'positive': 162, 'negative': 18, 'ratio': 8.578947368421053}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_by_threshold(freqs,label,threshold):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary of words\n",
        "        pos_neg_ratio: dictionary of positive counts, negative counts, and ratio of positive / negative counts.\n",
        "        label: 1 for positive, 0 for negative\n",
        "        threshold: ratio that will be used as the cutoff for including a word in the returned dictionary\n",
        "    Output:\n",
        "        word_set: dictionary containing the word and information on its positive count, negative count, and ratio of positive to negative counts.\n",
        "        example of a key value pair:\n",
        "        {'happi':\n",
        "            {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "        }\n",
        "    '''\n",
        "    word_list = []\n",
        "    for key in freqs.keys():\n",
        "        word, _ = key\n",
        "        pos_neg_ratio = get_ratio(freqs, word)\n",
        "        word_ratio_dict = {word: pos_neg_ratio}\n",
        "        if label == 1 and pos_neg_ratio['ratio'] >= threshold:\n",
        "            word_list.append(word_ratio_dict)\n",
        "        elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
        "\n",
        "            word_list.append(word_ratio_dict)\n",
        "\n",
        "    return word_list"
      ],
      "metadata": {
        "id": "eg7T8J8J-TwU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_words_by_threshold(freqs,label=0,threshold=0.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc2uESFuAY7I",
        "outputId": "b52c2e3c-6cd9-4c69-da5a-2e7489c8a2e0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{':(': {'positive': 1, 'negative': 3675, 'ratio': 0.000544069640914037}},\n",
              " {':(': {'positive': 1, 'negative': 3675, 'ratio': 0.000544069640914037}},\n",
              " {':-(': {'positive': 0, 'negative': 386, 'ratio': 0.002583979328165375}},\n",
              " {'zayniscomingbackonjuli': {'positive': 0, 'negative': 19, 'ratio': 0.05}},\n",
              " {'26': {'positive': 0, 'negative': 20, 'ratio': 0.047619047619047616}},\n",
              " {'>:(': {'positive': 0, 'negative': 43, 'ratio': 0.022727272727272728}},\n",
              " {'lost': {'positive': 0, 'negative': 19, 'ratio': 0.05}},\n",
              " {'♛': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996}},\n",
              " {'》': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996}},\n",
              " {'beli̇ev': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}},\n",
              " {'wi̇ll': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}},\n",
              " {'justi̇n': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}},\n",
              " {'ｓｅｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}},\n",
              " {'ｍｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Truth Predicted Tweet')\n",
        "for x,y in zip(test_x,test_y):\n",
        "    y_hat = naive_bayes_predict(x, logprior, loglikelihood)\n",
        "    if y != (np.sign(y_hat) > 0):\n",
        "        print ('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat)>0, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imw_n57qAas4",
        "outputId": "aef7b229-a1d4-4abf-df83-4f3606448d9e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truth Predicted Tweet\n",
            "1\t0.00\tb'truli later move know queen bee upward bound movingonup'\n",
            "1\t0.00\tb'new report talk burn calori cold work harder warm feel better weather :p'\n",
            "1\t0.00\tb'harri niall 94 harri born ik stupid wanna chang :d'\n",
            "1\t0.00\tb'park get sunlight'\n",
            "1\t0.00\tb'uff itna miss karhi thi ap :p'\n",
            "0\t1.00\tb'hello info possibl interest jonatha close join beti :( great'\n",
            "0\t1.00\tb'u prob fun david'\n",
            "0\t1.00\tb'pat jay'\n",
            "0\t1.00\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'I am happy because I am learning :)'\n",
        "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
        "print(p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy0I5iaLAzIm",
        "outputId": "79f62424-2710-4627-8390-b857e8a37476"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.570227756170972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "joblib.dump((logprior, loglikelihood), 'sentiment_model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaHtAQdiBjTl",
        "outputId": "db16c834-d7a3-4a38-aa8f-48aa8614d287"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sentiment_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qiXZ-VMkE7pn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}